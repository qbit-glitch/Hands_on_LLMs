{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae9c62a-08f7-4c98-bac9-4b542ee3d225",
   "metadata": {},
   "source": [
    "# Semantic Search and Retreival Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92763d77-a818-49f7-a775-9509046929b3",
   "metadata": {},
   "source": [
    "## Useful Resources\n",
    "\n",
    "1. https://oreil.ly/5NRQi\n",
    "2. https://oreil.ly/Bbnrd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885ef7e-0575-46ae-b44f-9f51ad5d3df2",
   "metadata": {},
   "source": [
    "## Overview Of Semantic Search and RAG\n",
    "\n",
    "Three broad categories of models based on their best use for search :\n",
    "- Dense Retrieval\n",
    "    - Relies on concept of embeddings and turn the search problem into retrieving the nearest neighbors of search queries.\n",
    "    - Dense retrieval takes a search query, consults it's archive of texts, and outputs a set of relevant results.\n",
    "    - Dense retrieval is one of the key types of semantic search, relying on the similarity of text embeddings to retrieve relevant results.\n",
    "- Re-Ranking :\n",
    "    - Rerankers, the second key type of semantic search, take a search queryand a collection of results, and reorder them by relevance, often resulting in vastly improved results.\n",
    "- RAG\n",
    "    - RAG are text generation systems that incorporate search\n",
    "capabilities to reduce hallucinations, increase factuality, and/or ground the generation model on a specific dataset.\n",
    "    - A RAG system formulates an answer to a question and preferably cites it's information sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d897f2-af6a-429e-b81d-915a0bc9dd1f",
   "metadata": {},
   "source": [
    "## Sematic search with Language Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f02cf-36c5-4702-8fc1-8ff73c379eac",
   "metadata": {},
   "source": [
    "### Dense Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6d841-0e1d-4324-9796-bda2563eba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"YOUR_COHERE_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a523076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and retrieve a Cohere API key from os.cohere.ai\n",
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Interstellar is a 2014 epic science fiction film co-written, directed, and pro\n",
    "duced by Christopher Nolan.\n",
    "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin,\n",
    "Ellen Burstyn, Matt Damon, and Michael Caine.\n",
    "Set in a dystopian future where humanity is struggling to survive, the film\n",
    "follows a group of astronauts who travel through a wormhole near Saturn in\n",
    "search of a new home for mankind. \n",
    "\n",
    "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its\n",
    "origins in a script Jonathan developed in 2007.\n",
    "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne\n",
    "was an executive producer, acted as a scientific consultant, and wrote a tie-in\n",
    "book, The Science of Interstellar.\n",
    "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision\n",
    "anamorphic format and IMAX 70 mm.\n",
    "Principal photography began in late 2013 and took place in Alberta, Iceland,\n",
    "and Los Angeles.\n",
    "\n",
    "Interstellar uses extensive practical and miniature effects and the company\n",
    "Double Negative created additional digital effects.\n",
    "Interstellar premiered on October 26, 2014, in Los Angeles.\n",
    "In the United States, it was first released on film stock, expanding to venues\n",
    "using digital projectors.\n",
    "The film had a worldwide gross over $677 million (and $773 million with subse\n",
    "quent re-releases),making it the tenth-highest grossing film of 2014.\n",
    "It received acclaim for its performances, direction, screenplay, musical score,\n",
    "visual effects, ambition, themes, and emotional weight.\n",
    "It has also received praise from many astronomers for its scientific accuracy\n",
    "and portrayal of theoretical astrophysics. Since its premiere, Interstellar\n",
    "gained a cult following,[5] and now is regarded by many sci-fi experts as one\n",
    "of the best science-fiction films of all time.\n",
    "Interstellar was nominated for five awards at the 87th Academy Awards, winning\n",
    "Best Visual Effects, and received numerous other accolades\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc97e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into a list of sentences\n",
    "texts = text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up to remove empty spaces and new lines\n",
    "texts = [t.strip('\\n') for t in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095a46e7",
   "metadata": {},
   "source": [
    "**Embedding the Text Chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c03652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings\n",
    "response = co.embed(\n",
    "    texts = texts,\n",
    "    input_type = \"search_document\",\n",
    ").embeddings\n",
    "\n",
    "embeds = np.array(response)\n",
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63caf7",
   "metadata": {},
   "source": [
    "**Building the Search Index**\n",
    "\n",
    "An index stores the embeddings and is optimized to quickly retrieve the nearest neighbors even if we have a very large number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73844290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "dim = embeds.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "print(index.is_trained)\n",
    "index.add(np.float32(embeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad62b95",
   "metadata": {},
   "source": [
    "**Search The Index**\n",
    "\n",
    "We can now search the dataset using any query we want. We simply\n",
    "embed the query and present its embedding to the index, which will retrieve the most similar sentence from the Wikipedia article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08083df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, number_of_results = 3):\n",
    "    # 1. Get the query's embeddings\n",
    "    query_embed = co.embed(\n",
    "        texts = [query],\n",
    "        input_type = \"search_query\"\n",
    "    ).embeddings[0]\n",
    "\n",
    "    # Retrieve the nearest neighbours\n",
    "    distances, similar_item_ids = index.search(np.float32([query_embed]), number_of_results)\n",
    "\n",
    "    # 3. Format the results\n",
    "    texts_np = np.array(texts)   # Convert texts list to numpy for easier indexing\n",
    "    results = pd.DataFrame(data = {\n",
    "        'tests': texts_np[similar_item_ids[0]],\n",
    "        'distance' : distances[0]\n",
    "    })\n",
    "\n",
    "    # Print and return the results\n",
    "    print(f\"Query: '{query}' \\nNearest neighbours:\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how precise was the science\"\n",
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3ace6-8017-47d0-ad89-b1d192854559",
   "metadata": {},
   "source": [
    "defining a keyword search function to compare the two. Weâ€™ll use the BM25 algorithm, which is one of the leading lexical search methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2d79a-968b-42b9-90bf-745f949f315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e5999-93e0-458c-a097-8bee57e471e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd7700-fa9f-4f95-9f5b-da5db4b580b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178d145-4fab-4a72-8f52-2b3b2d854610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(query, top_k = 3, num_candidates = 15):\n",
    "    print(\"Input Question: \", query)\n",
    "\n",
    "    ########## BM25 search (Lexical Search) ######################\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key = lambda x:x['score'], reverse = True)\n",
    "\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a1170-25da-453d-8fd1-3b1739f654a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_search(query = \"how precise was the science\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0e572-81d7-4e0c-a567-ed79c06f0281",
   "metadata": {},
   "source": [
    "## Re-Ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ca6ef-004b-4c63-8920-a805718f8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how precise was the science\"\n",
    "results = co.rerank(\n",
    "    query = query,\n",
    "    documents = texts,\n",
    "    top_n = 3,\n",
    "    return_documents = True\n",
    ")\n",
    "results.results\n",
    "\n",
    "# Print the results\n",
    "for idx, result in enumerate(results.results):\n",
    "    print(idx, result.relevance_score, result.document.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff1881-0821-4e92-a92a-a5b369d4b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_and_reranking_search(query, top_k = 3, num_candidates = 10):\n",
    "    print(\"Input Question : \", query)\n",
    "\n",
    "    ######### BM25 search (lexical search) ###################\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates: ]\n",
    "    bm25_hits = [{'corpus_id':idx, 'score':bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key= lambda x: x['score'], reverse = True)\n",
    "\n",
    "    print(f\"Top-3 lexical search (BM25) hits\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "\n",
    "    # Add reranking\n",
    "    docs = [texts[hit['corpus_id']] for hit in bm25_hits]\n",
    "\n",
    "    print(f\"\\nTop-3 hits by rank-API ({len(bm25_hits)} BM25 hits reranked)\")\n",
    "    results = co.rerank(query=query, documents = docs, top_n = top_k, return_documents = True)\n",
    "\n",
    "    # Print(results.results)\n",
    "    for hit in results.results:\n",
    "        # print(hit)\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit.relevance_score, hit.document.text.replace(\"\\n\", \" \")))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be4447-be33-4658-aa96-32d55c6d0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_and_reranking_search(query = \"how precise was the science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f5b01-30bd-461f-88fb-461c5279530b",
   "metadata": {},
   "source": [
    "## Grounded Generation with an LLM API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91270fec-e467-45d2-8d3d-82287fecff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"income generated\"\n",
    "\n",
    "# 1. Retrieval\n",
    "# We'll use embedding search. But ideally we'd do hybrid\n",
    "results = search('query')\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d3a73-0208-47ea-835e-570d6628e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Grounded Generation\n",
    "docs_dict = [{'text': text} for text in results['tests']]\n",
    "response = co.chat(\n",
    "    message = query,\n",
    "    documents = docs_dict\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c28613b-fbc5-496a-89f9-15785976354c",
   "metadata": {},
   "source": [
    "## Example : RAG with Local Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8ddb9-623d-438f-bdc6-c928aa590c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LlamaCpp\n",
    "\n",
    "# Make sure the model is correct for you system\n",
    "llm = LlamaCpp(\n",
    "    model_path = \"Phi-3-mini-4k-instruct-fp16.gguf\",\n",
    "    n_gpu_layers = -1,\n",
    "    max_tokens = 500,\n",
    "    n_ctx = 2048,\n",
    "    seed = 42,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e55c42-3a8f-407f-8b60-9ead96725cd2",
   "metadata": {},
   "source": [
    "### Load the embedding Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97088935-a0c0-4587-b80a-91cf5879d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee712cd-a04d-4dbb-a963-7a97ca107789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Model for converting text to numerical representations\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name = 'thenlper/gte-small'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f9a26-0cf0-4fc5-9e2a-62959fa3c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a local vector database\n",
    "db = FAISS.from_texts(texts, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23dd06-dc9d-4975-ba90-c036f7954392",
   "metadata": {},
   "source": [
    "### The RAG prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd186a-3dbf-4564-b8ca-98d2c6c7cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ddec7-ceb7-48ba-8599-5054af36ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template\n",
    "template = \"\"\"<|user|>\n",
    "Relevant Information:\n",
    "{context}\n",
    "\n",
    "Provide a concise answer the following question using the relevant information provided above:\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = template,\n",
    "    input_variables = [\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca21d8-d7b6-4a1d-83a2-33459ccb1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357fcce2-a1b7-4907-97eb-7eacfd746bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG pipeline\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    retriever = db.as_retriever(),\n",
    "    chain_type_kwargs = {'prompt': prompt},\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc62ea8-8298-4534-b340-6b3ffa6ed9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.invoke('Income Generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff73743-256d-4ec8-b3bc-deae2dfdddf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5d7f3-738d-4e51-b11d-9c571227c245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f9f3d-1641-4746-8f0f-fb2e287710e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3defd-aae3-49ce-8bfa-13a3768c5aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HandsOnLLMs",
   "language": "python",
   "name": "handsonllms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
